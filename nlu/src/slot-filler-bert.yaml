input_features:
  - name: text
    type: text
    encoder:
      type: bert
      trainable: true
      pretrained_model_name_or_path: google-bert/bert-base-multilingual-uncased

output_features:
  - name: slots
    type: sequence

preprocessing:
  split:
      type: random
      probabilities:
      - 0.85
      - 0.1
      - 0.05

trainer:
  batch_size: 32
  decay: true
  learning_rate: 0.00002
  epochs: 8
